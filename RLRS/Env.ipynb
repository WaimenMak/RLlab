{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 231903 entries, 0 to 260086\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   embedded_state   231903 non-null  object\n",
      " 1   embedded_action  231903 non-null  object\n",
      " 2   reward           231903 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 182.7 MB\n",
      "None\n",
      "77.52655625343323\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "from processing import train_data, embed\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class itemEnv():\n",
    "    def __init__(self, alpha = 0.4, sigma = 0.9): # albha parameter in consine similarity\n",
    "        self.observation_space = train_data\n",
    "        self.item_info = embed\n",
    "        self.current_state = None\n",
    "        self.init_state = self.reset()\n",
    "        self.sigma = sigma\n",
    "        self.alpha = alpha\n",
    "        self.embedding_dim = 7\n",
    "        self.reward_val = 1\n",
    "#         self.rewards, self.avg_state, self.avg_action, self.nx_size = self.avg_group()\n",
    "    \n",
    "    def reset(self):\n",
    "        init_state = self.observation_space['embedded_state'].sample(1).values[0]\n",
    "#         init_state = self.observation_space.loc[7,'embedded_state']\n",
    "        self.current_state = init_state\n",
    "        return init_state\n",
    "\n",
    "#     def feedback(self, pair):  # pair: state-action pair\n",
    "#         prob = list()\n",
    "#         denominator = 0.\n",
    "#         max_prob = 0.\n",
    "#         result = 0.\n",
    "#         feed_back = \"\"\n",
    "#         for r, s, a in zip(self.rewards, self.avg_state, self.avg_action):\n",
    "#             numerator = np.dot(pair[0], s.T) / np.linalg.norm(pair[0], 2) + np.dot(pair[1], a.T) / np.linalg.norm(pair[1], 2)\n",
    "#             denominator += numerator\n",
    "#             prob.append(numerator)\n",
    "#             if numerator > max_prob:\n",
    "#                 max_prob = numerator\n",
    "#                 feed_back = r\n",
    "#         prob = prob/denominator\n",
    "# #         for p, r in zip(prob, self.rewards):\n",
    "# #             for k in range(1):\n",
    "# #                 result += p * self.reward_val * np.power(self.sigma, k) * int(r.split(',')[k])\n",
    "        \n",
    "#         result = self.reward_val * int(feed_back.split(',')[0])\n",
    "#         print(prob)\n",
    "#         return feed_back, result\n",
    "\n",
    "    @staticmethod\n",
    "    def cos_sim(group, pair):\n",
    "        max_prob = 0.\n",
    "        # nx_size = len(group[1])\n",
    "        s_i = np.array(group[1]['embedded_state'].values.tolist()) # 2 dim array:0-->sample, 1-->feature_num (N,(7*12))\n",
    "        s_t = pair[0]                                              # 1 dim array:0-->sample, (7*12,)\n",
    "        a_i = np.array(group[1]['embedded_action'].values.tolist()) #(N,9,7)\n",
    "        a_t = pair[1]                                               #(7,)\n",
    "        norm_si = np.linalg.norm(s_i, 2, axis = 1)                 # 1 dim (N,)\n",
    "        norm_st = np.linalg.norm(s_t, 2, axis = 0)                 # 1 dim (1,)\n",
    "        norm_ai = np.linalg.norm(a_i, 2, axis = 2)                 # 2 dim (N, 9)\n",
    "        norm_at = np.linalg.norm(a_t, 2, axis = 0)                 # 1 dim (1,)\n",
    "        \n",
    "        #first term: (N,1), second term: (N,9)\n",
    "        cos = env.alpha * (np.dot(s_i, s_t)/(norm_si * norm_st + 1e-10))[:,np.newaxis] + (1 - env.alpha) * np.dot(a_i, a_t)/(norm_ai * norm_at + 1e-10)  #1 dim\n",
    "        # cos = cos / np.sum(cos)\n",
    "        #cos: (N,9)\n",
    "        max_id = np.argmax(cos)\n",
    "        id_x = int(max_id / cos.shape[1])\n",
    "        id_y = max_id % cos.shape[1]\n",
    "        # print('i am here!')\n",
    "        return (np.max(cos), id_x, id_y)\n",
    "    \n",
    "    def feedback_2(self, pair):\n",
    "        data = train_data.groupby(['reward'])\n",
    "#         denominator = 0.\n",
    "        reward_ind = -1\n",
    "        max_prob = 0.\n",
    "        result = 0.\n",
    "        feed_back = \"\"\n",
    "        fnc = partial(self.cos_sim, pair = pair)\n",
    "        prob = map(fnc, data)\n",
    "        for tup, group in zip(prob, data):\n",
    "            if tup[0] > max_prob:\n",
    "                max_prob = tup[0]\n",
    "                reward_ind = tup[2]  #id_y\n",
    "                feed_back = group[0]          #index: reward str\n",
    "#                 feed_back = group[1].iloc[tup[1], 2]\n",
    "#                 idx = tup[1]\n",
    "\n",
    "        r = 1 * int(feed_back.split(',')[reward_ind])  #reward_val\n",
    "        result =  r if r > 0 else -1\n",
    "\n",
    "        return feed_back, result\n",
    "            \n",
    "\n",
    "    def step(self, action):   #action: 1 dim array\n",
    "        feed_back, result = self.feedback_2((self.current_state, action))\n",
    "#         for i,r in enumerate([feed_back.split(',')[0]]): #0---> one action\n",
    "        if result == 1:     #reward_val\n",
    "            tmp = np.append(self.current_state, action)\n",
    "            tmp = tmp[self.embedding_dim:]\n",
    "            self.current_state = tmp  # state: 1 dim array\n",
    "#         else:\n",
    "#             self.current_state = self.observation_space['embedded_state'].sample(1).values[0]\n",
    "\n",
    "        return result, self.current_state, feed_back\n",
    "        \n",
    "#     def avg_group(self):\n",
    "#         nx_size = list()\n",
    "#         avg_state = list()\n",
    "#         avg_action = list()\n",
    "#         rewards = list()\n",
    "#         for reward, group in self.observation_space.groupby(['reward']):\n",
    "#             nx_size.append(group.shape[0])\n",
    "# #             state = np.mean(data['embedded_action'], axis = 0)\n",
    "#             norm_s = np.linalg.norm(np.array(group['embedded_state'].values.tolist()), 2, axis = 1)\n",
    "#             norm_s = np.where(norm_s == 0, 0.001, norm_s)\n",
    "#             state = np.sum(group['embedded_state'] / norm_s) / group.shape[0]\n",
    "#             norm_a = np.linalg.norm(np.array(group['embedded_action'].values.tolist()), 2, axis = 1)\n",
    "#             norm_a = np.where(norm_a == 0, 0.001, norm_a)\n",
    "#             action = np.sum(group['embedded_action'] / norm_a) / group.shape[0]\n",
    "#             avg_state.append(state)\n",
    "#             avg_action.append(action)\n",
    "#             rewards.append(reward)\n",
    "            \n",
    "#         return rewards, avg_state, avg_action, nx_size\n",
    "def gen_action(item_id):\n",
    "    return embed[item_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = itemEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.07092139,  2.46203633, -0.72387844, -0.12012139,\n",
       "         1.63520295, -0.73754373, -2.24228081,  0.97162306,  0.92553209,\n",
       "        -0.72387844, -0.10724431,  1.96710076, -0.89260205, -2.24228081,\n",
       "         0.07092139,  2.8461624 , -0.72387844, -0.12255155,  1.60967234,\n",
       "        -0.98937603, -2.24228081,  0.97162306,  2.8461624 , -0.72387844,\n",
       "        -0.12364443,  0.65774564, -0.84696432, -0.75910548, -0.82978028,\n",
       "        -0.61097216, -0.72387844, -0.12394348,  0.51550372, -0.92394362,\n",
       "        -0.75910548,  1.87232473, -0.2268461 , -0.72387844, -0.127393  ,\n",
       "         1.15741598, -0.66166413, -0.75910548,  0.07092139,  1.30965815,\n",
       "        -0.72387844, -0.11604297,  0.35502565,  2.16787524,  0.72406985,\n",
       "         0.07092139,  1.69378421, -0.72387844, -0.10893131,  1.20847718,\n",
       "         0.15651593,  0.72406985,  0.97162306,  0.92553209, -0.72387844,\n",
       "        -0.10724431,  1.96710076, -0.89260205, -2.24228081,  1.87232473,\n",
       "        -0.61097216, -0.72387844, -0.11864104,  2.04369257, -0.81397318,\n",
       "        -2.24228081,  0.97162306, -0.61097216, -0.72387844, -0.12460418,\n",
       "         1.43825259, -0.80352599, -2.24228081,  0.07092139,  1.69378421,\n",
       "        -0.72387844, -0.11545878,  1.79568101, -0.16789686, -0.75910548]), '0,0,0,0,0,0,0,0,0', 0.609839677810669)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "start = time.time()\n",
    "# action = train_data['embedded_action'].sample(1).values[0][5]\n",
    "# action = train_data.loc[0,'embedded_action'][0]\n",
    "action = gen_action(str(randint(1, 381)))\n",
    "r,s,f = env.step(action)\n",
    "end = time.time()\n",
    "r, s, f,end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([ 0.07092139,  1.69378421, -0.72387844, -0.10893131,  1.20847718,\n",
       "         0.15651593,  0.72406985,  0.07092139,  0.54140602, -0.72387844,\n",
       "        -0.11866091,  1.73732535, -0.82606993, -2.24228081,  0.07092139,\n",
       "        -0.61097216, -0.72387844, -0.12115068,  1.52213885, -1.04436125,\n",
       "        -2.24228081,  1.87232473, -0.61097216, -0.72387844, -0.12357091,\n",
       "         1.2230661 , -0.93494067, -2.24228081,  0.07092139, -0.61097216,\n",
       "        -0.72387844, -0.12258235,  1.53308054, -1.02236716, -0.75910548,\n",
       "         1.87232473,  0.15727996, -0.72387844, -0.11585022,  1.29601067,\n",
       "        -0.53959694, -0.75910548,  0.97162306,  0.92553209, -0.72387844,\n",
       "        -0.12226144,  1.55861114, -0.69410541, -0.75910548,  1.87232473,\n",
       "        -0.61097216, -0.72387844, -0.11926497,  0.36961457, -0.77438383,\n",
       "         0.72406985,  1.87232473,  0.92553209, -0.72387844, -0.11692224,\n",
       "         0.96776008, -0.8805053 ,  0.72406985,  1.87232473, -0.61097216,\n",
       "        -0.72387844, -0.11296006,  1.54402223, -0.8299189 , -2.24228081,\n",
       "         1.87232473, -0.61097216, -0.72387844, -0.12357091,  1.2230661 ,\n",
       "        -0.93494067, -2.24228081,  0.07092139,  0.54140602, -0.72387844,\n",
       "        -0.11866091,  1.73732535, -0.82606993, -2.24228081,  1.87232473,\n",
       "         0.15727996, -0.72387844, -0.11585022,  1.29601067, -0.53959694,\n",
       "        -0.75910548,  0.07092139, -0.61097216, -0.72387844, -0.12258235,\n",
       "         1.53308054, -1.02236716, -0.75910548,  0.07092139,  2.8461624 ,\n",
       "        -0.72387844, -0.12359178,  0.93858225, -1.00037308, -0.75910548,\n",
       "         1.87232473, -0.61097216, -0.72387844, -0.12207764,  0.53373986,\n",
       "        -0.5044064 ,  0.72406985,  0.97162306,  2.07791027, -0.72387844,\n",
       "        -0.12436871,  0.20548927,  0.54306202,  0.72406985, -0.82978028,\n",
       "         1.69378421, -0.72387844, -0.10210977,  0.60668444,  0.92300988,\n",
       "         0.72406985,  0.97162306, -0.2268461 , -0.72387844, -0.12719231,\n",
       "         1.08082417, -0.36804306, -0.75910548,  0.97162306,  0.15727996,\n",
       "        -0.72387844, -0.11658345,  2.09110654, -0.07497184, -2.24228081]), '1,1,1,1,1,1,1,1,0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = gen_action(str(randint(1, 381)))\n",
    "r,s,f= env.step(action)\n",
    "r, s, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reward\n",
       "0,0,0,0,0,0,0,0,0    21658\n",
       "0,0,1,0,0,0,0,0,0     5885\n",
       "0,1,0,0,0,0,0,0,0     6027\n",
       "0,1,0,1,0,0,1,0,0        1\n",
       "0,1,1,0,0,0,0,0,0     2940\n",
       "1,0,0,0,0,0,0,0,0     7280\n",
       "1,0,1,0,0,0,0,0,0     3228\n",
       "1,1,0,0,0,0,0,0,0     4519\n",
       "1,1,0,0,1,0,0,0,1        1\n",
       "1,1,1,0,0,0,0,0,0     5187\n",
       "1,1,1,0,0,1,0,0,0     4040\n",
       "1,1,1,0,1,0,0,0,0     3852\n",
       "1,1,1,0,1,1,0,0,0     3051\n",
       "1,1,1,1,0,0,0,0,0     4639\n",
       "1,1,1,1,0,1,0,0,0     3212\n",
       "1,1,1,1,1,0,0,0,0     4639\n",
       "1,1,1,1,1,1,0,0,0     3385\n",
       "1,1,1,1,1,1,0,0,1     4730\n",
       "1,1,1,1,1,1,0,1,0     7954\n",
       "1,1,1,1,1,1,0,1,1     6974\n",
       "1,1,1,1,1,1,1,0,0    10164\n",
       "1,1,1,1,1,1,1,0,1     8643\n",
       "1,1,1,1,1,1,1,1,0    33067\n",
       "1,1,1,1,1,1,1,1,1    26984\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('reward').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as act\n",
    "from torch.distributions import Categorical\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu():\n",
    "    i = 0\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1079,  0.0672,  0.1190, -0.0082,  0.0159, -0.0916, -0.1292, -0.0306,\n",
       "          0.1870, -0.1603,  0.0668, -0.1835,  0.1668, -0.0270,  0.0073,  0.0530,\n",
       "          0.0153, -0.1814, -0.0041, -0.0685, -0.1494,  0.1869, -0.1320,  0.1033,\n",
       "          0.0624, -0.0648,  0.1940, -0.0770,  0.1126,  0.1955,  0.0790, -0.0157,\n",
       "          0.1017, -0.0514,  0.1132, -0.1022,  0.2149, -0.1334,  0.1547,  0.1353,\n",
       "         -0.1803, -0.2086, -0.1818,  0.0882,  0.2047,  0.1095,  0.0558, -0.0535,\n",
       "         -0.0906, -0.0615,  0.1364, -0.1305,  0.1876, -0.1836, -0.0614, -0.0498,\n",
       "          0.2115, -0.1716,  0.0877, -0.1025, -0.0573, -0.1596, -0.1012,  0.1321,\n",
       "          0.1539,  0.0798,  0.1369, -0.1171,  0.0086, -0.1563,  0.1943, -0.1701,\n",
       "          0.0324,  0.1830, -0.1745,  0.1878,  0.0323, -0.1244,  0.0469,  0.1251,\n",
       "          0.1082,  0.0481,  0.1115, -0.0220, -0.1021,  0.0945, -0.1151, -0.0329,\n",
       "          0.0448, -0.0644, -0.1337, -0.0876,  0.1134,  0.1684, -0.1668,  0.1229,\n",
       "          0.0423, -0.1895,  0.0203, -0.0146, -0.0962, -0.2011,  0.1549,  0.0450,\n",
       "         -0.1802,  0.0218,  0.1572, -0.0023, -0.0014,  0.1066, -0.0667,  0.0122,\n",
       "         -0.2030, -0.2029, -0.1896, -0.1734, -0.0176, -0.0276, -0.0696, -0.0075,\n",
       "         -0.0089,  0.0493,  0.0150,  0.1603,  0.0669, -0.0629, -0.0362,  0.1255]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.bias_o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, inpt_sz, hidden_sz, hidden_l1, hidden_l2, oupt_sz): #embedding dim, , , 381\n",
    "        super().__init__()\n",
    "        #input_gate\n",
    "        device = try_gpu()\n",
    "        init_weights = partial(self.init_, device = device)\n",
    "#         self.init_state = None\n",
    "        self.reward = []\n",
    "        self.inpt_sz = inpt_sz\n",
    "        self.hidden_sz = hidden_sz\n",
    "        self.hidden_l1 = hidden_l1\n",
    "        self.hidden_l2 = hidden_l2\n",
    "        self.oupt_sz = oupt_sz\n",
    "        self.W_xi, self.W_hi, self.bias_i = (init_weights((inpt_sz, hidden_sz)), init_weights(\n",
    "                                            (hidden_sz, hidden_sz)), init_weights((1, hidden_sz))\n",
    "                                            )\n",
    "        #forget_gate\n",
    "        self.W_xf, self.W_hf, self.bias_f = (init_weights((inpt_sz, hidden_sz)), init_weights(\n",
    "                                            (hidden_sz, hidden_sz)), init_weights((1, hidden_sz))\n",
    "                                            )\n",
    "        #output_gate\n",
    "        self.W_xo, self.W_ho, self.bias_o = (init_weights((inpt_sz, hidden_sz)), init_weights(\n",
    "                                            (hidden_sz, hidden_sz)), init_weights((1, hidden_sz))\n",
    "                                            )\n",
    "        #candidate memory cell\n",
    "        self.W_xc, self.W_hc, self.bias_c = (init_weights((inpt_sz, hidden_sz)), init_weights(\n",
    "                                            (hidden_sz, hidden_sz)), init_weights((1, hidden_sz))\n",
    "                                            )\n",
    "        #output_layer\n",
    "        self.W_o1, self.W_o2, self.bias_o1, self.bias_o2 = (init_weights((hidden_sz, hidden_l1)), init_weights(\n",
    "                                            (hidden_l1, hidden_l2)), init_weights((1, hidden_l1)), \n",
    "                                            init_weights((1, hidden_l2))\n",
    "                                            ) \n",
    "        self.W_o3, self.bias_o3 = (init_weights((hidden_l2, oupt_sz)), \n",
    "                                            init_weights((1, oupt_sz)))\n",
    "    @staticmethod\n",
    "    def init_(shape, device):\n",
    "#         param = torch.tensor(shape)\n",
    "        def xvaier(param):\n",
    "            return nn.init.xavier_uniform_(param)\n",
    "        param = xvaier(torch.rand(shape, device = device))\n",
    "        return nn.Parameter(param)\n",
    "    \n",
    "    def forward(self, X, init_state = None):  #X: batch size, seq size, input size\n",
    "        batch_size, seq_size, _ = X.shape\n",
    "        hidden_sz = self.hidden_sz\n",
    "#         oupts = []\n",
    "        if init_state == None:         #H, C actually are constant, not trainable\n",
    "            H, C = (torch.zeros(batch_size, hidden_sz, device = X.device),\n",
    "                    torch.zeros(batch_size, hidden_sz, device = X.device)\n",
    "                   )\n",
    "        else:\n",
    "            H, C = init_state    # in some circumstance\n",
    "#         softmax = act.softmax(dim = 1)\n",
    "        for seq in range(seq_size):\n",
    "            x_t = X[:,seq,:]\n",
    "            I = torch.sigmoid(x_t @ self.W_xi + H @ self.W_hi + self.bias_i)\n",
    "            F = torch.sigmoid(x_t @ self.W_xf + H @ self.W_hf + self.bias_f)\n",
    "            O = torch.sigmoid(x_t @ self.W_xo + H @ self.W_ho + self.bias_o)\n",
    "            C_tilda = torch.tanh(x_t @ self.W_xc + H @ self.W_hc + self.bias_c)\n",
    "            \n",
    "            C = F * C + I * C_tilda\n",
    "            H = torch.tanh(C) + O\n",
    "            hidden_layer1 = torch.sigmoid(H @ self.W_o1 + self.bias_o1)\n",
    "            hidden_layer2 = torch.relu(hidden_layer1 @ self.W_o2 + self.bias_o2)\n",
    "            output = act.softmax(hidden_layer2 @ self.W_o3 + self.bias_o3, dim = 1)\n",
    "#             output = torch.relu(hidden_layer1 @ self.W_o2 + self.bias_o2)\n",
    "#             oupts.append(output)\n",
    "            \n",
    "#         self.init_state = (H, C)\n",
    "#         return torch.cat(oupts, dim = 0)\n",
    "        return output, (H, C)\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = LSTM(7, 64, 128, 256, 381)\n",
    "# actor.load_state_dict(torch.load('modelpara.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):\n",
    "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "start = time.time()\n",
    "device = try_gpu()\n",
    "# loss_fn = nn.NLLLoss(reduction='sum')\n",
    "state_num = 20\n",
    "max_episodes = 50\n",
    "max_episodes_len = 5\n",
    "gamma = 0.9\n",
    "optimizer = torch.optim.SGD(actor.parameters(), lr = 0.01)\n",
    "for episode in range(max_episodes):\n",
    "    env.reset()\n",
    "    state = env.current_state\n",
    "    for j in range(2):\n",
    "    #     env.current_state = train_data.loc[7,'embedded_state']\n",
    "        env.current_state = state\n",
    "#         G_t = 0.\n",
    "    #     bat_x = []\n",
    "    #     target = []\n",
    "        policy_loss_l = []\n",
    "        reward_l = []\n",
    "        optimizer.zero_grad()\n",
    "        for i in range(max_episodes_len):\n",
    "            n_state = np.reshape(env.current_state, [-1, state_num, 7])\n",
    "#             n_state = torch.from_numpy(n_state).cuda().to(torch.float32)\n",
    "            n_state = torch.from_numpy(n_state).to(device).to(torch.float32)\n",
    "#             bat_x.append(n_state)\n",
    "            prob, _= actor(n_state)\n",
    "\n",
    "#             prob = act.softmax(prob, dim = 1)\n",
    "            m = Categorical(prob)\n",
    "#             action = m.sample() if np.random.random() > 0.2 else torch.randint(0, 381, [1]).cuda()  #0~380 [low, high)\n",
    "            action = m.sample() if np.random.random() > 0.2 else torch.randint(0, 381, [1]).to(device)  #0~380 [low, high)\n",
    "    #         action = m.sample()\n",
    "    #         target.append(action)\n",
    "            with torch.no_grad():\n",
    "                embed_action = gen_action(str(action.item() + 1))  #action : char\n",
    "                r, _, _ = env.step(embed_action)\n",
    "#             G_t = gamma*G_t + r\n",
    "            reward_l.append(r)\n",
    "            policy_loss_l.append(-m.log_prob(action))\n",
    "            print(f'{action.item()}:{r}',end = ' ')\n",
    "#         print(f'\\nproba:{prob[0][action.item()]}')\n",
    "        \n",
    "        for k in range(max_episodes_len - 1):\n",
    "            reward_l[max_episodes_len-k-2] = reward_l[max_episodes_len-k-2] + gamma * reward_l[max_episodes_len-k-1]\n",
    "        policy_loss_l = [a * b for a, b in zip(policy_loss_l, reward_l)]\n",
    "\n",
    "        loss = torch.cat(policy_loss_l).sum()  \n",
    "        loss.backward()\n",
    "    #     bat_x = torch.cat(bat_x, 0)\n",
    "    #     target = torch.cat(target, -1)\n",
    "    #     pred, _ = actor(bat_x)\n",
    "    #     log_prob = torch.log(pred)\n",
    "    #     loss = loss_fn(G_t * log_prob, target)\n",
    "\n",
    "    #     loss.backward()\n",
    "    #     sgd(actor.parameters(), 0.1, max_episodes_len)\n",
    "        optimizer.step()\n",
    "\n",
    "#         pr, _= actor(n_state)\n",
    "#         with torch.no_grad():\n",
    "#             pr = act.softmax(pr, dim = 1)\n",
    "#         print(f'after:{pr[0][action.item()]}')\n",
    "        print(f'total reward:{sum(reward_l)}, loss:{loss.data}')\n",
    "\n",
    "end = time.time()\n",
    "end - start\n",
    "# aa = torch.cat(aa, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[177, 271, 187, 280, 282, 309,  92, 178, 147,  80,  66, 291, 272, 313,\n",
       "         240, 276,  43, 129, 369, 226,  90, 115, 261, 344, 324,  68, 224, 301,\n",
       "         284, 251,  61, 343,  64, 117, 329, 326, 353, 315, 270,  77, 289, 246,\n",
       "         285, 158, 376, 250,  36,  62, 346, 121, 252, 361, 103, 110, 189, 288,\n",
       "         268,  32, 210, 207, 373, 322, 194, 356,  95, 354, 151, 308, 230,  71,\n",
       "         132, 294,   1, 222, 287, 120,  72, 283, 135, 156, 328, 336,  60, 235,\n",
       "         304,  37,   6, 139, 217,  58, 325, 286, 300, 278, 146, 331, 114,  42,\n",
       "         215, 267, 321, 297, 157,   0, 296, 327, 173, 126, 319,  28, 352, 239,\n",
       "          74,  55, 176, 244, 231,  93,  81,  12, 236, 137, 152,  34, 112, 174,\n",
       "         275, 364, 228, 274, 201,  84, 248,  13, 310, 155, 264, 171,  23, 323,\n",
       "         293,  41, 179, 273,  98, 229, 257,  88, 299, 247, 167, 124, 379, 290,\n",
       "         292, 341,  57, 365,  31, 371, 237,  99,  14,  38, 165, 123, 233, 214,\n",
       "           3, 104, 186, 100, 258,  35, 111,  53,  46, 130, 221, 211, 196, 140,\n",
       "          17, 318, 340,  10, 262, 195,  75, 142,   5, 227, 180, 191, 181, 337,\n",
       "          18,  87,  51,  70, 360, 202, 128, 175,  83,  44, 218, 107,  50, 367,\n",
       "          29, 143, 368, 306,  73, 359, 348, 232, 134, 312, 101, 314, 245, 320,\n",
       "         242, 163, 338,  59, 131,   8, 277,  54, 253, 256, 141,  19,  86, 350,\n",
       "          40, 249, 203,  30, 119, 225, 259, 351,  25, 184,   7, 266, 125, 223,\n",
       "          15, 127, 161, 145, 209, 265, 136, 206, 164, 160, 219, 238, 263,   9,\n",
       "         281,   4,  48, 295, 216, 269, 298, 105, 377, 362, 166, 374,  22, 169,\n",
       "         113,  11,  24, 153, 255, 330,  89, 144, 183, 148, 335, 349,  56,  65,\n",
       "          63, 185, 234,  79, 363, 358,  33, 378, 333,  49, 303, 154, 254, 305,\n",
       "         345, 106,  20, 204,  76, 118, 162, 355, 260, 188, 198, 357, 307, 150,\n",
       "         199,   2, 213,  97, 334, 116, 149,  96,  45, 102, 380, 190, 197, 170,\n",
       "         316, 212, 220,  52, 208, 159,  16, 370, 138, 193,  94,  21, 243,  91,\n",
       "         347,  69,  78, 182, 372, 366, 192, 302, 122, 342, 205, 108, 317,  85,\n",
       "          39, 168, 375, 279,  47,  67, 241, 200, 311, 109,  82, 133,  26, 172,\n",
       "         339,  27, 332]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_state = np.reshape(train_data.loc[10,'embedded_state'], [-1, state_num, 7])\n",
    "n_state = torch.from_numpy(n_state).cuda().to(torch.float32)\n",
    "prob, _= actor(n_state)\n",
    "prob.sort()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[177, 280, 187, 271,  92, 309, 282, 178,  66,  80, 147, 313,  43, 291,\n",
       "         272, 240, 115, 226, 326, 276, 369, 344,  68, 324, 129, 284,  77, 261,\n",
       "         224,  61,  90, 301, 270, 329, 246, 251, 353, 343, 376,  64, 158, 117,\n",
       "          62, 315,  32, 250, 285, 346, 189, 110, 121,  36, 289, 322, 252, 308,\n",
       "         294, 210, 361, 103, 283, 135,  95, 207, 356, 287, 194, 373,  72, 268,\n",
       "         230, 151, 304, 288, 300, 120,  71, 354,  37, 156, 235, 217,  42, 321,\n",
       "         336, 328, 146,   1, 222, 278,   6,  28, 297, 325, 319, 286, 364,   0,\n",
       "         157,  58, 132,  13,  74, 327, 126, 275, 139, 173, 331, 267, 112,  12,\n",
       "          60,  93, 323, 352, 176, 174, 257, 239, 179, 137, 264, 296, 248, 247,\n",
       "         244, 215, 201, 114, 171, 231, 290,  55, 214,   3,  88, 310, 152,  23,\n",
       "         379, 236, 299, 100,  38, 274, 124, 341, 221,  98, 228,  81, 123,  99,\n",
       "          34,  35, 293,  14, 211, 155, 229, 130,  41,  84, 318, 273, 237, 292,\n",
       "          31, 180,  57, 140, 371,   5, 181, 258, 365, 337, 111, 306, 134, 104,\n",
       "         191,  83, 165, 340, 186,  17, 196, 227, 128, 233,  87, 167,  18,  10,\n",
       "          70, 348,  46, 262,  44, 107, 360, 367, 256, 142, 202, 175, 350,  53,\n",
       "         101, 195,  29,  75, 320,  19, 312, 314, 225, 131, 338,   8, 143, 359,\n",
       "         218,  73,  54, 232, 245, 368, 277,  50, 253, 259, 164, 223, 141,  51,\n",
       "         163, 166, 160, 351, 265, 242, 249, 136, 219, 269,  59, 298, 145, 263,\n",
       "         266,  86,  15, 206, 203, 295, 161, 113,  30, 255, 184, 119, 349,   4,\n",
       "         281, 238,   7,  22, 148,  25, 335,   9, 144, 105, 362, 153,  40, 363,\n",
       "         374, 154, 127, 209, 330, 125,  33, 377, 169,  89,  11, 358,  24, 183,\n",
       "         254, 333,  65, 185,  20,  49, 199, 303,  48, 216, 345, 355, 260, 234,\n",
       "           2,  79,  63, 106, 334, 307, 118, 378,  56, 305, 188, 204, 150, 197,\n",
       "         213, 149, 198, 220,  76, 380, 170, 357, 208, 316,  45,  97, 116,  16,\n",
       "          94, 162, 347, 190, 366, 302, 102, 192,  78, 122, 212, 159,  96,  69,\n",
       "          91, 182, 372,  52, 138, 193,  21, 205, 370, 243,  39, 317,  85, 342,\n",
       "         375, 108, 279,  67, 168, 200,  82,  47, 133, 241, 172, 311, 109,  26,\n",
       "         339, 332,  27]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_state = np.reshape(train_data.loc[1,'embedded_state'], [-1, state_num, 7])\n",
    "n_state = torch.from_numpy(n_state).cuda().to(torch.float32)\n",
    "prob, _= actor(n_state)\n",
    "prob.sort()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.97162306, -0.61097216, -0.72387844, -0.12398621,  1.2741273 ,\n",
       "        -0.44447251, -0.75910548, -0.82978028, -0.61097216, -0.72387844,\n",
       "        -0.12344275,  0.59574275, -0.36199468, -0.75910548,  0.07092139,\n",
       "         2.07791027, -0.72387844, -0.12306521,  1.26318561,  0.36875888,\n",
       "        -0.75910548,  0.07092139,  1.69378421, -0.72387844, -0.10893131,\n",
       "         1.20847718,  0.15651593,  0.72406985,  1.87232473,  0.15727996,\n",
       "        -0.72387844, -0.1105289 ,  2.03639811, -0.49011024, -2.24228081,\n",
       "         0.97162306, -0.61097216, -0.72387844, -0.12460418,  1.43825259,\n",
       "        -0.80352599, -2.24228081,  0.97162306, -0.61097216, -0.72387844,\n",
       "        -0.12244425,  1.31424681, -0.67211132, -2.24228081,  1.87232473,\n",
       "        -0.2268461 , -0.72387844, -0.11831516,  1.46013597, -0.96188342,\n",
       "        -0.75910548,  0.97162306, -0.2268461 , -0.72387844, -0.12726186,\n",
       "         1.0078796 , -0.3652938 , -0.75910548,  0.07092139,  2.8461624 ,\n",
       "        -0.72387844, -0.12359178,  0.93858225, -1.00037308, -0.75910548,\n",
       "         0.97162306,  0.92553209, -0.72387844, -0.12189185,  0.49362034,\n",
       "        -0.50220699,  0.72406985,  0.07092139,  0.15727996, -0.72387844,\n",
       "        -0.12199717,  0.33678951,  0.64863364,  0.72406985]),\n",
       " [104, 51, 78, 196, 29, 22, 24, 125, 120, 85, 212, 184])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[10,'embedded_state'], train_data.loc[10,'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0000e+00, 0.0000e+00, 1.0000e+00, 4.1750e-03, 4.3600e-01,\n",
       "        1.4400e+03, 2.0000e+00, 2.0000e+00, 7.0000e+00, 1.0000e+00,\n",
       "        3.3960e-03, 2.0100e-01, 1.6621e+04, 3.0000e+00, 3.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 7.7120e-03, 7.2100e-01, 9.5400e+02,\n",
       "        1.0000e+00, 4.0000e+00, 0.0000e+00, 1.0000e+00, 4.9990e-03,\n",
       "        6.4500e-01, 5.9600e+02, 1.0000e+00, 4.0000e+00, 4.0000e+00,\n",
       "        1.0000e+00, 2.5387e-02, 8.5100e-01, 2.9500e+02, 1.0000e+00,\n",
       "        4.0000e+00, 7.0000e+00, 1.0000e+00, 6.4600e-03, 5.3200e-01,\n",
       "        1.5570e+03, 2.0000e+00, 2.0000e+00, 7.0000e+00, 1.0000e+00,\n",
       "        6.5770e-03, 6.7400e-01, 2.9540e+03, 1.0000e+00, 2.0000e+00,\n",
       "        7.0000e+00, 1.0000e+00, 6.5770e-03, 6.7400e-01, 2.9540e+03,\n",
       "        1.0000e+00, 2.0000e+00, 2.0000e+00, 1.0000e+00, 1.5764e-02,\n",
       "        8.3300e-01, 2.9540e+03, 1.0000e+00, 2.0000e+00, 2.0000e+00,\n",
       "        1.0000e+00, 1.5764e-02, 8.3300e-01, 2.9540e+03, 1.0000e+00,\n",
       "        4.0000e+00, 0.0000e+00, 1.0000e+00, 3.5580e-03, 6.1100e-01,\n",
       "        3.9800e+02, 1.0000e+00, 2.0000e+00, 2.0000e+00, 1.0000e+00,\n",
       "        1.5764e-02, 8.3300e-01, 2.9540e+03, 1.0000e+00]),\n",
       " [51, 192, 18, 38, 28, 132, 7, 7, 1, 1, 37, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[1,'embedded_state'], train_data.loc[1,'state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0031, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[(0)][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 11, 25, 57, 51, 72, 149, 152, 233]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[7,'action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.87232473,  2.07791027, -0.72387844, -0.12089336,  0.78539864,\n",
       "       -0.0766214 ,  0.72406985])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_action('239')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.87232473, -0.61097216, -0.72387844, -0.12432599,  0.73069021,\n",
       "       -0.85796136, -0.75910548])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_action('134')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,1,0,0,0,0,0,0,0'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[7,'reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, array([3.33333333e-01, 3.33333333e-01, 0.00000000e+00, 8.35436814e-04,\n",
       "        6.36897767e-01, 1.75459899e-02, 5.00000000e-01, 3.33333333e-01,\n",
       "        6.66666667e-01, 0.00000000e+00, 1.95080676e-03, 7.09753231e-01,\n",
       "        1.35571611e-01, 1.00000000e+00, 3.33333333e-01, 6.66666667e-01,\n",
       "        0.00000000e+00, 1.95080676e-03, 7.09753231e-01, 1.35571611e-01,\n",
       "        1.00000000e+00, 3.33333333e-01, 6.66666667e-01, 0.00000000e+00,\n",
       "        1.95080676e-03, 7.09753231e-01, 1.35571611e-01, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.11111111e-01, 0.00000000e+00, 9.23104185e-04,\n",
       "        5.19388954e-01, 3.61240969e-02, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.11111111e-01, 0.00000000e+00, 9.23104185e-04, 5.19388954e-01,\n",
       "        3.61240969e-02, 1.00000000e+00, 3.33333333e-01, 2.22222222e-01,\n",
       "        0.00000000e+00, 1.63742707e-03, 9.78848414e-01, 1.70238601e-01,\n",
       "        0.00000000e+00, 3.33333333e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.30244215e-03, 9.11868390e-01, 1.76067027e-03, 0.00000000e+00,\n",
       "        6.66666667e-01, 7.77777778e-01, 0.00000000e+00, 6.32991663e-04,\n",
       "        9.17743831e-01, 1.10982940e-01, 0.00000000e+00, 3.33333333e-01,\n",
       "        1.11111111e-01, 0.00000000e+00, 7.90045058e-04, 8.14336075e-01,\n",
       "        4.54131504e-02, 5.00000000e-01, 3.33333333e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.27713931e-04, 5.55816686e-01, 5.40343634e-03,\n",
       "        5.00000000e-01, 0.00000000e+00, 4.44444444e-01, 0.00000000e+00,\n",
       "        4.08629669e-04, 4.38307873e-01, 8.98548965e-02, 5.00000000e-01]), '1,1,1,1,1,1,0,1,0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_state = train_data.loc[0,'embedded_state']\n",
    "action = gen_action('151')\n",
    "r,s,f= env.step(action)\n",
    "r, s, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(actor.state_dict(),'modelpara.pth')\n",
    "# actor = actor.load_state_dict(torch.load('modelpara.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.07092139, -0.61097216, -0.72387844,\n",
       "       -0.11225565,  1.59508343, -0.82771949, -2.24228081])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[7,'embedded_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-161.3674, -155.0946, -156.8075,  ..., -153.8318, -187.5206,\n",
       "         -160.8493],\n",
       "        [-157.4997, -150.8772, -152.9312,  ..., -150.8477, -182.5345,\n",
       "         -156.8122],\n",
       "        [-156.8636, -150.4019, -152.0855,  ..., -150.4251, -181.2172,\n",
       "         -156.2092],\n",
       "        ...,\n",
       "        [-155.1541, -148.4594, -150.3322,  ..., -148.8944, -179.0215,\n",
       "         -154.5119],\n",
       "        [-155.1541, -148.4594, -150.3322,  ..., -148.8944, -179.0215,\n",
       "         -154.5119],\n",
       "        [-155.1541, -148.4594, -150.3322,  ..., -148.8944, -179.0215,\n",
       "         -154.5119]], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_t * pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([358, 307], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000023CC7FCE480>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(group, x):\n",
    "    max_prob = 0.\n",
    "    nx_size = len(group)\n",
    "    \n",
    "    for i in range(nx_size):\n",
    "        tmp = group.loc[i,'two'] + x\n",
    "        if tmp > max_prob:\n",
    "            max_prob = tmp\n",
    "    print(max_prob)\n",
    "    return max_prob\n",
    "        \n",
    "    \n",
    "pool = ProcessPoolExecutor(max_workers=8)\n",
    "for _ in pool.map(compare, (aa.groupby('one'), 1)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  one              two  three\n",
      "0   1  [1.0, 1.0, 1.0]      3\n",
      "2   1  [0.0, 0.0, 0.0]      5\n",
      "  one              two  three\n",
      "1   2  [0.0, 0.0, 0.0]      4\n",
      "3   2  [1.0, 1.0, 1.0]      8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "one\n",
       "1    2\n",
       "2    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group in aa.groupby('one'):   \n",
    "    print(group[1])\n",
    "aa.groupby('one').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1.5 1.5 1.5]\n",
      "0\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for group in aa.groupby('one'):   \n",
    "    i = np.argmax(group[1]['three'].values.tolist())\n",
    "    print(i)\n",
    "    print(group[1].iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 0.]\n",
      "[0. 3.]\n"
     ]
    }
   ],
   "source": [
    "for group in aa.groupby('one'):\n",
    "    print(np.dot(np.array(group[1]['two'].values.tolist()), np.ones(3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "[[0. 0. 0.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "for group in aa.groupby('one'):\n",
    "    print(np.array(group[1]['two'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.73205081        nan]\n",
      "[       nan 1.73205081]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for group in aa.groupby('one'):\n",
    "    a = np.array(group[1]['two'].values.tolist())\n",
    "    n = np.linalg.norm(a,2,axis = 1)\n",
    "    d = np.dot(a, np.ones(3))\n",
    "    print(d/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import long_time_task\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = np.array([[1,2,3],[4,5,6]])\n",
    "np.max(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_2 = np.linalg.norm(np.array(train_data['embedded_action'].values.tolist()), 2, axis = 1)\n",
    "norm_2 = np.where(norm_2 == 0, 0.001, norm_2)\n",
    "norm_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(train_data.loc[0,'embedded_state'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(train_data['embedded_action'] / norm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = train_data['embedded_action'] / norm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(bb[5], bb[5].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[],2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.info(memory_usage = 'deep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['reward'] = train_data['reward'].apply(lambda row: str(row))\n",
    "group_data = train_data.groupby('reward')  \n",
    "for index, data in group_data:\n",
    "    print(type(index))\n",
    "#     print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
